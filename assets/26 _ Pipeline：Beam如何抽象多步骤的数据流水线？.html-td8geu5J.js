import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,a as n,o as t}from"./app-d8EKP-K0.js";const o={};function i(p,e){return t(),r("div",null,e[0]||(e[0]=[n(`<h1 id="_26-pipeline-beam如何抽象多步骤的数据流水线" tabindex="-1"><a class="header-anchor" href="#_26-pipeline-beam如何抽象多步骤的数据流水线"><span>26 _ Pipeline：Beam如何抽象多步骤的数据流水线？</span></a></h1><p><audio id="audio" title="26 | Pipeline：Beam如何抽象多步骤的数据流水线？" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/14/74/14aa9d734f5d452f9009d179eb14d274.mp3"></audio></p><p>你好，我是蔡元楠。</p><p>今天我要与你分享的主题是“Pipeline：Beam如何抽象多步骤的数据流水线”。</p><p>在上两讲中，我们一起学习了Beam是如何抽象封装数据，以及如何抽象对于数据集的转换操作的。在掌握了这两个基本概念后，我们就可以很好地回答Beam编程模型里的4个维度What、Where、When、How中的第一个问题——What了。也就是，我们要做什么计算？想得到什么样的结果？</p><img src="https://static001.geekbang.org/resource/image/71/bb/71c8ace006d56d7f6fe93cbc56dc91bb.png" alt="unpreview"><p>这个时候你可能已经跃跃欲试，开始想用PCollection和Transform解决我们平常经常会使用到的批处理任务了。没有问题，那我们就先抛开Where、When和How这三个问题，由简至繁地讲起。</p><p>现在假设我们的数据处理逻辑只需要处理有边界数据集，在这个情况下，让我们一起来看看Beam是如何运行一套批处理任务的。</p><h2 id="数据流水线" tabindex="-1"><a class="header-anchor" href="#数据流水线"><span>数据流水线</span></a></h2><p>在Beam的世界里，所有的数据处理逻辑都会被抽象成**数据流水线（Pipeline）**来运行。那么什么是数据流水线呢？</p><p>Beam的数据流水线是对于数据处理逻辑的一个封装，它包括了从<strong>读取数据集</strong>，<strong>将数据集转换成想要的结果</strong>和<strong>输出结果数据集</strong>这样的一整套流程。</p><p>所以，如果我们想要跑自己的数据处理逻辑，就必须在程序中创建一个Beam数据流水线出来，比较常见的做法是在main()函数中直接创建。</p><p>Java</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>PipelineOptions options = PipelineOptionsFactory.create();</span></span>
<span class="line"><span>Pipeline p = Pipeline.create(options);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>在创建Beam数据流水线的同时，我们必须给这个流水线定义一个<strong>选项</strong>（Options）。这个选项会告诉Beam，用户的Pipeline应该如何运行。例如，是在本地的内存上运行，还是在Apache Flink上运行？关于具体Beam选项的解释，我会在第30讲中展开讲解。</p><h2 id="beam数据流水线的应用" tabindex="-1"><a class="header-anchor" href="#beam数据流水线的应用"><span>Beam数据流水线的应用</span></a></h2><p>有了数据流水线这个抽象概念之后，我们就可以将PCollection和Transform应用在这个流水线里面了。</p><img src="https://static001.geekbang.org/resource/image/a5/94/a56f824d0dc8b3c1a777595b42c4b294.jpg" alt=""><p>上图就是一个Beam的数据流水线，整个数据流水线包括了从读取数据，到经过了N个Transform之后输出数据的整个过程。</p><p>在<a href="https://time.geekbang.org/column/article/100666" target="_blank" rel="noopener noreferrer">第24讲</a>中我们学习过PCollection的不可变性。也就是说，一个PCollection一经生成，我们就不能够再增加或者删除它里面的元素了。所以，在Beam的数据流水线中，每次PCollection经过一个Transform之后，流水线都会新创建一个PCollection出来。而这个新的PCollection又将成为下一个Transform的新输入。</p><img src="https://static001.geekbang.org/resource/image/47/4b/47e4856cfdcb771c135417741d4d044b.jpg" alt=""><p>在上图的示例中，Beam数据流水线在经过Transform1读取了输入数据集之后，会创建出一个新的PCollection1，而经过了Transform2之后，数据流水线又会创建出新的PCollection2出来，同时PCollection1不会有任何改变。也就是说，在上面的例子中，除去最终的输出结果，数据流水线一共创建了3个不同的PCollection出来。</p><p>这种特性可以让我们在编写数据处理逻辑的时候，对同一个PCollection应用多种不同的Transfrom。</p><p>例如下图所示，对于PCollection1，我们可以使三个不同的Transform应用在它之上，从而再产生出三个不同的PCollection2、PCollection3和PCollection4出来。</p><img src="https://static001.geekbang.org/resource/image/ee/ef/eeb81605c09e4a6cc684176ef0a9c9ef.jpg" alt=""><h2 id="beam数据流水线的处理模型" tabindex="-1"><a class="header-anchor" href="#beam数据流水线的处理模型"><span>Beam数据流水线的处理模型</span></a></h2><p>在了解完Beam数据流水线高度抽象的概念后，紧接着，我想和你介绍一下Beam数据流水线的处理模型，也就是数据流水线在运行起来之后，会发生些什么，它是如何处理我们定义好的PCollection和Transform的。</p><p>Beam数据流水线的底层思想其实还是动用了MapReduce的原理，在分布式环境下，整个数据流水线会启动N个Workers来同时处理PCollection。而在具体处理某一个特定Transform的时候，数据流水线会将这个Transform的输入数据集PCollection里面的元素分割成不同的Bundle，将这些Bundle分发给不同的Worker来处理。</p><p>Beam数据流水线具体会分配多少个Worker，以及将一个PCollection分割成多少个Bundle都是随机的。但Beam数据流水线会尽可能地让整个处理流程达到<strong>完美并行</strong>（Embarrassingly Parallel）。</p><p>我想举个几个例子让你更好地来理解这个概念。</p><p>假设在数据流水线的一个Transform里面，它的输入数据集PCollection是1、2、3、4、5、6这个6个元素。数据流水线可能会将这个PCollection按下图的方式将它分割成两个Bundles。</p><img src="https://static001.geekbang.org/resource/image/1e/1d/1ec163043a8e8e18928ed4771cac671d.jpg" alt=""><p>当然，PCollection也有可能会被分割成三个Bundles。</p><img src="https://static001.geekbang.org/resource/image/87/2b/87c924863790f3564949b416a98a6c2b.jpg" alt=""><p>那数据流水线会启用多少个Worker来处理这些Bundle呢？这也是任意的。还是以刚刚的PCollection输入数据集作为例子，如果PCollection被分割成了两个Bundles，数据流水线有可能会分配两个Worker来处理这两个Bundles。</p><img src="https://static001.geekbang.org/resource/image/32/33/32cf33cae5a581b6b5d5739bfe775533.jpg" alt=""><p>甚至有可能只分配一个Worker来处理这两个Bundles。</p><img src="https://static001.geekbang.org/resource/image/d8/29/d8d53d23ea0d507055e003cb2e07cb29.jpg" alt=""><p>在多步骤的Transforms中，一个Bundle通过一个Transform产生出来的结果会作为下一个Transform的输入。</p><p>之前刚刚讲过，在Beam数据流水线中，抽象出来的PCollection经过一个Transform之后，流水线都会新创建一个PCollection出来。同样的，Beam在真正运行的时候，每一个Bundle在一个Worker机器里经过Transform逻辑后，也会产生出来一个新的Bundle，它们也是具有不可变性的。像这种具有关联性的Bundle，必须在同一个Worker上面处理。</p><p>我现在来举例说明一下上面的概念。现在假设输入数据集如下图所示，它被分成了两个Bundles。</p><img src="https://static001.geekbang.org/resource/image/1e/1d/1ec163043a8e8e18928ed4771cac671d.jpg" alt=""><p>我们现在需要做两个Transforms。第一个Transform会将元素的数值减一；第二个Transform会对元素的数值求平方。整个过程被分配到了两个Workers上完成。</p><img src="https://static001.geekbang.org/resource/image/57/fd/574e866c6609c6551083d55ff534cffd.jpg" alt=""><p>过程就如上图所示，总共产生了6个不可变的Bundle出来，从Bundle1到Bundle3的整个过程都必须放在Worker1上完成，因为它们都具有关联性。同样的，从Bundle4到Bundle6的整个过程也都必须放在Worker2上完成。</p><h2 id="beam数据流水线的错误处理" tabindex="-1"><a class="header-anchor" href="#beam数据流水线的错误处理"><span>Beam数据流水线的错误处理</span></a></h2><p>在学习完Beam数据流水线底层的处理模型之后，你可能会有个疑问：既然Bundle都是放在分布式环境下处理的，要是其中一个步骤出错了，那数据流水线会做什么样的处理？接下来我会给你讲解一下Beam数据流水线的错误处理机制。</p><h3 id="单个transform上的错误处理" tabindex="-1"><a class="header-anchor" href="#单个transform上的错误处理"><span>单个Transform上的错误处理</span></a></h3><p>我们还是以单个Transform开始讲解。在一个Transform里面，如果某一个Bundle里面的元素因为任意原因导致处理失败了，则这整个Bundle里的元素都必须重新处理。</p><p>还是假设输入数据集如下图所示，被分成了两个Bundles。</p><img src="https://static001.geekbang.org/resource/image/32/33/32cf33cae5a581b6b5d5739bfe775533.jpg" alt=""><p>Beam数据流水线分配了两个Worker来处理这两个Bundles。我们看到下图中，在Worker2处理Bundle2的时候，最后一个元素6处理失败了。</p><img src="https://static001.geekbang.org/resource/image/e4/91/e4e87019b6e646073a4234348c346091.jpg" alt=""><p>这个时候，即便Bundle2的元素5已经完成了处理，但是因为同一个Bundle里面的元素处理失败，所以整个Bundle2都必须拿来重新处理。</p><img src="https://static001.geekbang.org/resource/image/2c/7b/2c80f7616367535a4bae5d036d75ff7b.jpg" alt=""><p>重新处理的Bundle也不一定要在原来的Worker里面被处理，有可能会被转移到另外的Worker里面处理。如上图所示，需要重新被处理的Bundle2就被转移到Worker1上面处理了。</p><h3 id="多步骤transform上的错误处理" tabindex="-1"><a class="header-anchor" href="#多步骤transform上的错误处理"><span>多步骤Transform上的错误处理</span></a></h3><p>学习完单个Transform上的错误处理机制，我们再来看看在多步骤的Transform上发生错误时是如何处理的。</p><p>在多步骤的Transform上，如果处理的一个Bundle元素发生错误了，则这个元素所在的整个Bundle以及与这个Bundle有关联的所有Bundle都必须重新处理。</p><p>我们还是用上面的多步骤Transform来讲解这个例子。</p><img src="https://static001.geekbang.org/resource/image/93/25/939e3cf386d5ae416dd878743d98be25.jpg" alt=""><p>你可以看到，在Worker2中，处理Transform2逻辑的时候生成Bundle6里面的第一个元素失败了。因为Bundle4、Bundle5和Bundle6都是相关联的，所以这三个Bundle都会被重新处理。</p><h2 id="小结" tabindex="-1"><a class="header-anchor" href="#小结"><span>小结</span></a></h2><p>今天我们一起学习了Beam里对于数据处理逻辑的高度抽象数据流水线，以及它的底层处理模型。数据流水线是构建数据处理的基础，掌握了它，我们就可以根据自身的应用需求，构建出一套数据流水线来处理数据。</p><h2 id="思考题" tabindex="-1"><a class="header-anchor" href="#思考题"><span>思考题</span></a></h2><p>你能根据自己的理解重述一下在Beam的数据流水线中，当处理的元素发生错误时流水线的错误处理机制吗？</p><p>欢迎你把答案写在留言区，与我和其他同学一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。</p>`,67)]))}const c=a(o,[["render",i]]),m=JSON.parse('{"path":"/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%AE%9E%E6%88%98/%E6%A8%A1%E5%9D%97%E5%9B%9B%20_%20Apache%20Beam%E4%B8%BA%E4%BD%95%E8%83%BD%E4%B8%80%E7%BB%9F%E6%B1%9F%E6%B9%96/26%20_%20Pipeline%EF%BC%9ABeam%E5%A6%82%E4%BD%95%E6%8A%BD%E8%B1%A1%E5%A4%9A%E6%AD%A5%E9%AA%A4%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%9F.html","title":"26 _ Pipeline：Beam如何抽象多步骤的数据流水线？","lang":"zh-CN","frontmatter":{"description":"26 _ Pipeline：Beam如何抽象多步骤的数据流水线？ 你好，我是蔡元楠。 今天我要与你分享的主题是“Pipeline：Beam如何抽象多步骤的数据流水线”。 在上两讲中，我们一起学习了Beam是如何抽象封装数据，以及如何抽象对于数据集的转换操作的。在掌握了这两个基本概念后，我们就可以很好地回答Beam编程模型里的4个维度What、Where...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/interview/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%AE%9E%E6%88%98/%E6%A8%A1%E5%9D%97%E5%9B%9B%20_%20Apache%20Beam%E4%B8%BA%E4%BD%95%E8%83%BD%E4%B8%80%E7%BB%9F%E6%B1%9F%E6%B9%96/26%20_%20Pipeline%EF%BC%9ABeam%E5%A6%82%E4%BD%95%E6%8A%BD%E8%B1%A1%E5%A4%9A%E6%AD%A5%E9%AA%A4%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%9F.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"26 _ Pipeline：Beam如何抽象多步骤的数据流水线？"}],["meta",{"property":"og:description","content":"26 _ Pipeline：Beam如何抽象多步骤的数据流水线？ 你好，我是蔡元楠。 今天我要与你分享的主题是“Pipeline：Beam如何抽象多步骤的数据流水线”。 在上两讲中，我们一起学习了Beam是如何抽象封装数据，以及如何抽象对于数据集的转换操作的。在掌握了这两个基本概念后，我们就可以很好地回答Beam编程模型里的4个维度What、Where..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-16T11:19:38.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-16T11:19:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"26 _ Pipeline：Beam如何抽象多步骤的数据流水线？\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-08-16T11:19:38.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1755343178000,"updatedTime":1755343178000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":1,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":8.18,"words":2454},"filePathRelative":"posts/大规模数据处理实战/模块四 _ Apache Beam为何能一统江湖/26 _ Pipeline：Beam如何抽象多步骤的数据流水线？.md","localizedDate":"2025年8月16日","excerpt":"\\n<p><audio id=\\"audio\\" title=\\"26 | Pipeline：Beam如何抽象多步骤的数据流水线？\\" controls=\\"\\" preload=\\"none\\"><source id=\\"mp3\\" src=\\"https://static001.geekbang.org/resource/audio/14/74/14aa9d734f5d452f9009d179eb14d274.mp3\\"></audio></p>\\n<p>你好，我是蔡元楠。</p>\\n<p>今天我要与你分享的主题是“Pipeline：Beam如何抽象多步骤的数据流水线”。</p>\\n<p>在上两讲中，我们一起学习了Beam是如何抽象封装数据，以及如何抽象对于数据集的转换操作的。在掌握了这两个基本概念后，我们就可以很好地回答Beam编程模型里的4个维度What、Where、When、How中的第一个问题——What了。也就是，我们要做什么计算？想得到什么样的结果？</p>","autoDesc":true}');export{c as comp,m as data};
