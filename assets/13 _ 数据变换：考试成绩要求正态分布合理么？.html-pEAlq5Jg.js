import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as e,o as i}from"./app-d8EKP-K0.js";const p={};function r(l,s){return i(),a("div",null,s[0]||(s[0]=[e(`<h1 id="_13-数据变换-考试成绩要求正态分布合理么" tabindex="-1"><a class="header-anchor" href="#_13-数据变换-考试成绩要求正态分布合理么"><span>13 _ 数据变换：考试成绩要求正态分布合理么？</span></a></h1><p><audio id="audio" title="13 | 数据变换：考试成绩要求正态分布合理么？" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/d1/aa/d1b2ccd5d623553c4df34e4993a71aaa.mp3"></audio></p><p>上一讲中我给你讲了数据集成，今天我来讲下数据变换。</p><p>如果一个人在百分制的考试中得了95分，你肯定会认为他学习成绩很好，如果得了65分，就会觉得他成绩不好。如果得了80分呢？你会觉得他成绩中等，因为在班级里这属于大部分人的情况。</p><p>为什么会有这样的认知呢？这是因为我们从小到大的考试成绩基本上都会满足正态分布的情况。什么是正态分布呢？正态分布也叫作常态分布，就是正常的状态下，呈现的分布情况。</p><p>比如你可能会问班里的考试成绩是怎样的？这里其实指的是大部分同学的成绩如何。以下图为例，在正态分布中，大部分人的成绩会集中在中间的区域，少部分人处于两头的位置。正态分布的另一个好处就是，如果你知道了自己的成绩，和整体的正态分布情况，就可以知道自己的成绩在全班中的位置。</p><img src="https://static001.geekbang.org/resource/image/e7/f5/e77a79d3c483c93e74933becd92b5af5.jpg" alt=""><p>另一个典型的例子就是，美国SAT考试成绩也符合正态分布。而且美国本科的申请，需要中国高中生的GPA在80分以上（百分制的成绩），背后的理由也是默认考试成绩属于正态分布的情况。</p><p>为了让成绩符合正态分布，出题老师是怎么做的呢？他们通常可以把考题分成三类：</p><p>第一类：基础题，占总分70%，基本上属于送分题；</p><p>第二类：灵活题，基础范围内+一定的灵活性，占20%；</p><p>第三类：难题，涉及知识面较广的难题，占10%；</p><p>那么，你想下，如果一个出题老师没有按照上面的标准来出题，而是将第三类难题比重占到了70%，也就是我们说的“超纲”，结果会是怎样呢？</p><p>你会发现，大部分人成绩都“不及格”，最后在大家激烈的讨论声中，老师会将考试成绩做规范化处理，从而让成绩满足正态分布的情况。因为只有这样，成绩才更具有比较性。所以正态分布的成绩，不仅可以让你了解全班整体的情况，还能了解每个人的成绩在全班中的位置。</p><h2 id="数据变换在数据分析中的角色" tabindex="-1"><a class="header-anchor" href="#数据变换在数据分析中的角色"><span>数据变换在数据分析中的角色</span></a></h2><p>我们再来举个例子，假设A考了80分，B也考了80分，但前者是百分制，后者500分是满分，如果我们把从这两个渠道收集上来的数据进行集成、挖掘，就算使用效率再高的算法，结果也不是正确的。因为这两个渠道的分数代表的含义完全不同。</p><p>所以说，有时候数据变换比算法选择更重要，数据错了，算法再正确也是错的。你现在可以理解为什么80%的工作时间会花在前期的数据准备上了吧。</p><p>那么如何让不同渠道的数据统一到一个目标数据库里呢？这样就用到了数据变换。</p><p>在数据变换前，我们需要先对字段进行筛选，然后对数据进行探索和相关性分析，接着是选择算法模型（这里暂时不需要进行模型计算），然后针对算法模型对数据的需求进行数据变换，从而完成数据挖掘前的准备工作。</p><p><img src="https://static001.geekbang.org/resource/image/90/e9/9081a928916973723e66d70c771162e9.jpg" alt=""><br><br> 所以你从整个流程中可以看出，数据变换是数据准备的重要环节，它<strong>通过数据平滑、数据聚集、数据概化和规范化等方式</strong>将数据转换成适用于数据挖掘的形式。</p><p>我来介绍下这些常见的变换方法：</p><p><strong>数据平滑</strong>：去除数据中的噪声，将连续数据离散化。这里可以采用分箱、聚类和回归的方式进行数据平滑，我会在后面给你讲解聚类和回归这两个算法；</p><p><strong>数据聚集</strong>：对数据进行汇总，在SQL中有一些聚集函数可以供我们操作，比如Max()反馈某个字段的数值最大值，Sum()返回某个字段的数值总和；</p><p><strong>数据概化</strong>：将数据由较低的概念抽象成为较高的概念，减少数据复杂度，即用更高的概念替代更低的概念。比如说上海、杭州、深圳、北京可以概化为中国。</p><p><strong>数据规范化</strong>：使属性数据按比例缩放，这样就将原来的数值映射到一个新的特定区域中。常用的方法有最小—最大规范化、Z—score 规范化、按小数定标规范化等，我会在后面给你讲到这些方法的使用；</p><p><strong>属性构造</strong>：构造出新的属性并添加到属性集中。这里会用到特征工程的知识，因为通过属性与属性的连接构造新的属性，其实就是特征工程。比如说，数据表中统计每个人的英语、语文和数学成绩，你可以构造一个“总和”这个属性，来作为新属性。这样“总和”这个属性就可以用到后续的数据挖掘计算中。</p><p>在这些变换方法中，最简单易用的就是对数据进行规范化处理。下面我来给你讲下如何对数据进行规范化处理。</p><h2 id="数据规范化的几种方法" tabindex="-1"><a class="header-anchor" href="#数据规范化的几种方法"><span>数据规范化的几种方法</span></a></h2><p><strong>1. Min-max 规范化</strong></p><p>Min-max规范化方法是将原始数据变换到[0,1]的空间中。用公式表示就是：</p><p>新数值=（原数值-极小值）/（极大值-极小值）。</p><p><strong>2. Z-Score 规范化</strong></p><p>假设A与B的考试成绩都为80分，A的考卷满分是100分（及格60分），B的考卷满分是500分（及格300分）。虽然两个人都考了80分，但是A的80分与B的80分代表完全不同的含义。</p><p>那么如何用相同的标准来比较A与B的成绩呢？Z-Score就是用来可以解决这一问题的。</p><p>我们定义：新数值=（原数值-均值）/ 标准差。</p><p>假设A所在的班级平均分为80，标准差为10。B所在的班级平均分为400，标准差为100。那么A的新数值=(80-80)/10=0，B的新数值=(80-400)/100=-3.2。</p><p>那么在Z-Score标准下，A的成绩会比B的成绩好。</p><p>我们能看到Z-Score的优点是算法简单，不受数据量级影响，结果易于比较。不足在于，它需要数据整体的平均值和方差，而且结果没有实际意义，只是用于比较。</p><p><strong>3.小数定标规范化</strong></p><p>小数定标规范化就是通过移动小数点的位置来进行规范化。小数点移动多少位取决于属性A的取值中的最大绝对值。</p><p>举个例子，比如属性A的取值范围是-999到88，那么最大绝对值为999，小数点就会移动3位，即新数值=原数值/1000。那么A的取值范围就被规范化为-0.999到0.088。</p><p>上面这三种是数值规范化中常用的几种方式。</p><h2 id="python的scikit-learn库使用" tabindex="-1"><a class="header-anchor" href="#python的scikit-learn库使用"><span>Python的SciKit-Learn库使用</span></a></h2><p>SciKit-Learn是Python的重要机器学习库，它帮我们封装了大量的机器学习算法，比如分类、聚类、回归、降维等。此外，它还包括了数据变换模块。</p><p>我现在来讲下如何使用SciKit-Learn进行数据规范化。</p><p><strong>1. Min-max 规范化</strong></p><p>我们可以让原始数据投射到指定的空间[min, max]，在SciKit-Learn里有个函数MinMaxScaler是专门做这个的，它允许我们给定一个最大值与最小值，然后将原数据投射到[min, max]中。默认情况下[min,max]是[0,1]，也就是把原始数据投放到[0,1]范围内。</p><p>我们来看下下面这个例子：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span># coding:utf-8</span></span>
<span class="line"><span>from sklearn import preprocessing</span></span>
<span class="line"><span>import numpy as np</span></span>
<span class="line"><span># 初始化数据，每一行表示一个样本，每一列表示一个特征</span></span>
<span class="line"><span>x = np.array([[ 0., -3.,  1.],</span></span>
<span class="line"><span>              [ 3.,  1.,  2.],</span></span>
<span class="line"><span>              [ 0.,  1., -1.]])</span></span>
<span class="line"><span># 将数据进行[0,1]规范化</span></span>
<span class="line"><span>min_max_scaler = preprocessing.MinMaxScaler()</span></span>
<span class="line"><span>minmax_x = min_max_scaler.fit_transform(x)</span></span>
<span class="line"><span>print minmax_x</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>运行结果：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>[[0.         0.         0.66666667]</span></span>
<span class="line"><span> [1.         1.         1.        ]</span></span>
<span class="line"><span> [0.         1.         0.        ]]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>2. Z-Score规范化</strong></p><p>在SciKit-Learn库中使用preprocessing.scale()函数，可以直接将给定数据进行Z-Score规范化。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>from sklearn import preprocessing</span></span>
<span class="line"><span>import numpy as np</span></span>
<span class="line"><span># 初始化数据</span></span>
<span class="line"><span>x = np.array([[ 0., -3.,  1.],</span></span>
<span class="line"><span>              [ 3.,  1.,  2.],</span></span>
<span class="line"><span>              [ 0.,  1., -1.]])</span></span>
<span class="line"><span># 将数据进行Z-Score规范化</span></span>
<span class="line"><span>scaled_x = preprocessing.scale(x)</span></span>
<span class="line"><span>print scaled_x</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>运行结果：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>[[-0.70710678 -1.41421356  0.26726124]</span></span>
<span class="line"><span> [ 1.41421356  0.70710678  1.06904497]</span></span>
<span class="line"><span> [-0.70710678  0.70710678 -1.33630621]]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这个结果实际上就是将每行每列的值减去了平均值，再除以方差的结果。</p><p>我们看到Z-Score规范化将数据集进行了规范化，数值都符合均值为0，方差为1的正态分布。</p><p><strong>3. 小数定标规范化</strong></p><p>我们需要用NumPy库来计算小数点的位数。NumPy库我们之前提到过。</p><p>这里我们看下运行代码：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span># coding:utf-8</span></span>
<span class="line"><span>from sklearn import preprocessing</span></span>
<span class="line"><span>import numpy as np</span></span>
<span class="line"><span># 初始化数据</span></span>
<span class="line"><span>x = np.array([[ 0., -3.,  1.],</span></span>
<span class="line"><span>              [ 3.,  1.,  2.],</span></span>
<span class="line"><span>              [ 0.,  1., -1.]])</span></span>
<span class="line"><span># 小数定标规范化</span></span>
<span class="line"><span>j = np.ceil(np.log10(np.max(abs(x))))</span></span>
<span class="line"><span>scaled_x = x/(10**j)</span></span>
<span class="line"><span>print scaled_x</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>运行结果：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>[[ 0.  -0.3  0.1]</span></span>
<span class="line"><span> [ 0.3  0.1  0.2]</span></span>
<span class="line"><span> [ 0.   0.1 -0.1]]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="数据挖掘中数据变换比算法选择更重要" tabindex="-1"><a class="header-anchor" href="#数据挖掘中数据变换比算法选择更重要"><span>数据挖掘中数据变换比算法选择更重要</span></a></h2><p>在考试成绩中，我们都需要让数据满足一定的规律，达到规范性的要求，便于进行挖掘。这就是数据变换的作用。</p><p>如果不进行变换的话，要不就是维数过多，增加了计算的成本，要不就是数据过于集中，很难找到数据之间的特征。</p><p>在数据变换中，重点是如何将数值进行规范化，有三种常用的规范方法，分别是Min-Max规范化、Z-Score规范化、小数定标规范化。其中Z-Score规范化可以直接将数据转化为正态分布的情况，当然不是所有自然界的数据都需要正态分布，我们也可以根据实际的情况进行设计，比如取对数log，或者神经网络里采用的激励函数等。</p><img src="https://static001.geekbang.org/resource/image/e7/e9/e764dc178b5dffd919907fdd0d175ae9.jpg" alt=""><p>在最后我给大家推荐了Python的sklearn库，它和NumPy, Pandas都是非常有名的Python库，在数据统计工作中起了很大的作用。SciKit-Learn不仅可以用于数据变换，它还提供了分类、聚类、预测等数据挖掘算法的API封装。后面我会详细给你讲解这些算法，也会教你如何使用SciKit-Learn工具来完成数据挖掘算法的工作。</p><p>最后给你留道思考题吧，假设属性income的最小值和最大值分别是5000元和58000元。利用Min-Max规范化的方法将属性的值映射到0至1的范围内，那么属性income的16000元将被转化为多少？</p><p>另外数据规范化都有哪些方式，他们是如何进行规范化的？欢迎在评论区与我分享你的答案，也欢迎你把这篇文章分享给你的朋友或者同事，一起讨论一下。</p>`,72)]))}const c=n(p,[["render",r]]),o=JSON.parse('{"path":"/posts/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/%E7%AC%AC%E4%B8%80%E6%A8%A1%E5%9D%97%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80%E7%AF%87/13%20_%20%E6%95%B0%E6%8D%AE%E5%8F%98%E6%8D%A2%EF%BC%9A%E8%80%83%E8%AF%95%E6%88%90%E7%BB%A9%E8%A6%81%E6%B1%82%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%90%88%E7%90%86%E4%B9%88%EF%BC%9F.html","title":"13 _ 数据变换：考试成绩要求正态分布合理么？","lang":"zh-CN","frontmatter":{"description":"13 _ 数据变换：考试成绩要求正态分布合理么？ 上一讲中我给你讲了数据集成，今天我来讲下数据变换。 如果一个人在百分制的考试中得了95分，你肯定会认为他学习成绩很好，如果得了65分，就会觉得他成绩不好。如果得了80分呢？你会觉得他成绩中等，因为在班级里这属于大部分人的情况。 为什么会有这样的认知呢？这是因为我们从小到大的考试成绩基本上都会满足正态分布...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/interview/posts/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/%E7%AC%AC%E4%B8%80%E6%A8%A1%E5%9D%97%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80%E7%AF%87/13%20_%20%E6%95%B0%E6%8D%AE%E5%8F%98%E6%8D%A2%EF%BC%9A%E8%80%83%E8%AF%95%E6%88%90%E7%BB%A9%E8%A6%81%E6%B1%82%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%90%88%E7%90%86%E4%B9%88%EF%BC%9F.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"13 _ 数据变换：考试成绩要求正态分布合理么？"}],["meta",{"property":"og:description","content":"13 _ 数据变换：考试成绩要求正态分布合理么？ 上一讲中我给你讲了数据集成，今天我来讲下数据变换。 如果一个人在百分制的考试中得了95分，你肯定会认为他学习成绩很好，如果得了65分，就会觉得他成绩不好。如果得了80分呢？你会觉得他成绩中等，因为在班级里这属于大部分人的情况。 为什么会有这样的认知呢？这是因为我们从小到大的考试成绩基本上都会满足正态分布..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-16T11:19:38.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-16T11:19:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"13 _ 数据变换：考试成绩要求正态分布合理么？\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-08-16T11:19:38.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1755343178000,"updatedTime":1755343178000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":1,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":9.82,"words":2946},"filePathRelative":"posts/数据分析实战45讲/第一模块：数据分析基础篇/13 _ 数据变换：考试成绩要求正态分布合理么？.md","localizedDate":"2025年8月16日","excerpt":"\\n<p><audio id=\\"audio\\" title=\\"13 | 数据变换：考试成绩要求正态分布合理么？\\" controls=\\"\\" preload=\\"none\\"><source id=\\"mp3\\" src=\\"https://static001.geekbang.org/resource/audio/d1/aa/d1b2ccd5d623553c4df34e4993a71aaa.mp3\\"></audio></p>\\n<p>上一讲中我给你讲了数据集成，今天我来讲下数据变换。</p>\\n<p>如果一个人在百分制的考试中得了95分，你肯定会认为他学习成绩很好，如果得了65分，就会觉得他成绩不好。如果得了80分呢？你会觉得他成绩中等，因为在班级里这属于大部分人的情况。</p>","autoDesc":true}');export{c as comp,o as data};
