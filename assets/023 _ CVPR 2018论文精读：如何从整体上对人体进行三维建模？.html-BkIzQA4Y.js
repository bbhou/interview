import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,a,o as r}from"./app-d8EKP-K0.js";const n={};function p(s,t){return r(),e("div",null,t[0]||(t[0]=[a('<h1 id="_023-cvpr-2018论文精读-如何从整体上对人体进行三维建模" tabindex="-1"><a class="header-anchor" href="#_023-cvpr-2018论文精读-如何从整体上对人体进行三维建模"><span>023 _ CVPR 2018论文精读：如何从整体上对人体进行三维建模？</span></a></h1><p><audio id="audio" title="023 | CVPR 2018论文精读：如何从整体上对人体进行三维建模？" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/81/f4/8183ffd2d1c3e1c4a1c07bef6b80e0f4.mp3"></audio></p><p>今天我们来分享CVPR大会的最佳学生论文，标题是《全方位捕捉：用于跟踪面部表情，手势和身体运动的3D变形模型》（<a href="http://www.cs.cmu.edu/~hanbyulj/totalbody/totalcapture.pdf" target="_blank" rel="noopener noreferrer">Total Capture: A 3D Deformation Model for Tracking Faces, Hands and Bodies</a>）。</p><p>很多学术会议都利用最佳学生论文这个奖项来鼓励学生参与学术研究活动，所以这个奖项的一般要求是第一作者必须是在校学生。</p><p>这篇论文的作者群来自卡内基梅隆大学。</p><p>第一作者周寒星（Hanbyul Joo）是来自韩国的学者，目前在卡内基梅隆大学机器人学院（The Robotics Institute）攻读博士。他的博士论文方向是“计算行为科学”（Computational Behavioral Science）。他已经在计算机视觉方向发表了多篇CVPR、ICCV论文。</p><p>第二作者托马斯·西蒙（Tomas Simon）也是卡内基梅隆大学机器人学院的博士生。他的研究方向是“三维运动的时空建模”（Spatiotemporal Modeling of 3D Motion）。</p><p>最后一位作者是这两位学生的导师亚瑟尔·舍艾克（Yaser Sheikh），是机器人学院的教授。</p><h2 id="论文的主要贡献" tabindex="-1"><a class="header-anchor" href="#论文的主要贡献"><span>论文的主要贡献</span></a></h2><p>这篇论文想要解决的问题很直观，那就是希望对人体进行三维建模，并且能够跟踪（Track）人体的行为以及活动。</p><p>这个任务看似简单，但有不少难点。</p><p>首先，过去绝大多数的对人体进行三维建模的工作，都是针对人体的不同部分分别进行的，比如对脸部、对身体和对手部分别建模。在对这些部位进行建模的时候，整体的设定都不太一样。例如，对脸部的建模一般是近景（Close-Up），而对身体则主要是看身体的整体行动。也就是，对于人体不同部位的建模经常在不同的尺度下进行，那就无法把各个部分的建模很容易地对接上。</p><p>其次，还有一些人体的部位，过去并没有太多专门的建模工作，比如针对头发和脚，但这些在全身的建模中也是必不可少的部分。</p><p>这篇论文就加入了对头发和脚这些部分建模的讨论，提供了对人体从整体上进行建模的一个框架。确切地说，论文提供了两个模型：一个叫“弗兰肯斯坦”（Frankenstein），一个叫“亚当”（Adam）。</p><p>“弗兰肯斯坦”主要还是依靠对人体不同部分的建模，然后把这些模型连接起来，通过一些处理，能够让最终呈现的三维建模符合现实。在这个模型的基础上，“亚当”则加入了头发和脚的元素，抛弃了“弗兰肯斯坦”的一些特殊处理的地方，从模型的角度来说更加简单，并且达到了更加逼真的程度。</p><h2 id="论文的核心方法" tabindex="-1"><a class="header-anchor" href="#论文的核心方法"><span>论文的核心方法</span></a></h2><p>首先，我们来看一看这个叫“弗兰肯斯坦”的模型。这个模型的思路是尽量把能够对人体各个部分建模的最好的模型先拼接到一起。总体来说，每一个部分基本上都由三组参数组成：<strong>运动参数</strong>（Motion Parameters）、<strong>形状参数</strong>（Shape Parameters）和<strong>全局翻译参数</strong>（Global Translation Parameter）。</p><p>对于人的身体部分，作者们采用了<strong>SMPL模型</strong>[1]。这个模型根据<strong>人体形状的均值</strong>和<strong>形状的变化量</strong>进行线性的叠加，然后经过一个<strong>LBS变换</strong>来得到对身体部分的最终建模。</p><p>对人脸的部分，作者们采用了一个叫<strong>FaceWarehouse的模型</strong>[2]。这个模型是根据<strong>人脸形状的均值</strong>、<strong>形状的变化量，<strong>以及</strong>动态的变化量</strong>来进行线性的叠加。</p><p>对于手而言，目前并没有模型可以直接用。作者们在这篇论文中<strong>提出了自己的模型</strong>，总的来说就是对手的骨架和关节进行建模，然后进行类似于身体的LBS变换。同样，也对人体的脚进行了类似的建模。</p><p>当我们有了身体、人脸、手和脚的模型以后，下面的工作就是把这些部分衔接上。首先，作者们保留了人体模型，移除这个模型上的人脸、手和脚。然后利用人脸模型、手的模型以及脚的模型相应的全局翻译参数，使得这些部分的坐标能够拼接上。最后，作者们还应用了一个“<strong>融合函数</strong>”来构建出一个平滑的人体结构。</p><p>“弗兰肯斯坦”的模型有一个<strong>四项的目标优化函数</strong>。这个函数的第一项是拟合“<strong>关键点</strong>”（Key Points），让人体的躯干骨架能够拟合上运动轨迹。第二项是拟合“<strong>三维点云</strong>”（3D Point Cloud），也就是让人体大部分躯体的实体能够拟合运动轨迹。第三项就是作者们附加的一个“小技巧”（Heuristic）用来把人体的每个部分连接在一起。这一项解决的就是整个模型设计带来的问题，也就是每个部分都是单独的形状参数，而并没有完全在模型上连接起来。最后一项是<strong>高斯先验概率</strong>，用来帮助模型找到唯一的解。</p><p>在“弗兰肯斯坦”的基础上，作者们开发了“亚当”模型。为了构建“亚当”，他们捕捉了70个人体的形态数据，首先构建这些人体的“弗兰肯斯坦”模型。在这些模型基础之上，作者们加入了人体的<strong>头发和衣服的形态</strong>，并且重新定义了整个模型的框架。</p><p>和“弗兰肯斯坦”相比，“亚当”是对所有的人体部件直接进行建模。这个模型和我们前面描述的某个具体部分的模型其实很类似，也是把人体的形态均值、形态的变化值和人脸表现值进行线性叠加，然后进行LBS变换。</p><p>因为“亚当”在模型上进行了简化和创新，所以在目标优化函数中只有三项变量。而我们刚刚讲过的用于“弗兰肯斯坦”模型的小技巧在“亚当”中就变得不需要了。</p><h2 id="实验结果" tabindex="-1"><a class="header-anchor" href="#实验结果"><span>实验结果</span></a></h2><p>在实验中，作者们使用了140个VGA照相机对三维身体的关键点进行重建，用了480个VGA照相机，对脚进行重建，31个高清照相机用于脸部和手部关键点的重建以及三维点云的构建。</p><p>作者们显示了利用“弗兰肯斯坦”和“亚当”这两个模型对人体的三维运动进行建模。总体来说，这两个模型的表现非常相似。“亚当”因为有了头发和衣服的形态，在运动中显得更加真实。只是在有一些情况下，“亚当”构建的腿会显得有一些不协调的瘦，出现这种情况的原因，作者们归结于数据的缺失。</p><p>不过，从总体效果上来讲，这篇论文作为第一个对于人体的全身进行三维建模并动态跟踪的工作，应该算是达到了满意的结果。</p><h2 id="小结" tabindex="-1"><a class="header-anchor" href="#小结"><span>小结</span></a></h2><p>今天我为你讲了CVPR 2018的最佳学生论文。</p><p>一起来回顾下要点：第一，我们详细介绍了这篇文章要解决的问题，就是从整体上对人体的运动进行三维建模；第二，我们简要介绍了文章提出的两个模型，“弗兰肯斯坦”和“亚当”核心内容；第三，我们简单介绍了这篇论文所取得的不错的实验结果。</p><p>最后，给你留一个思考题，如果我们需要对“亚当”这个模型进行改进，你认为下一步应该做什么？</p><p>欢迎你给我留言，和我一起讨论。</p><p><strong>参考文献</strong></p><ol><li><p>M. Loper, N. Mahmood, J. Romero, G. Pons-Moll, and M. J. Black. <strong>SMPL: A Skinned Multi-Person Linear Model</strong>. In TOG, 2015.</p></li><li><p>C. Cao, Y. Weng, S. Zhou, Y. Tong, and K. Zhou. <strong>FaceWareHouse: A 3D Facial Expression Database for Visual Computing</strong>. In TVCG, 2014.</p></li></ol>',36)]))}const d=o(n,[["render",p]]),B=JSON.parse('{"path":"/posts/AI%E6%8A%80%E6%9C%AF%E5%86%85%E5%8F%82/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9B%BD%E9%99%85%E9%A1%B6%E7%BA%A7%E4%BC%9A%E8%AE%AE/023%20_%20CVPR%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BB%8E%E6%95%B4%E4%BD%93%E4%B8%8A%E5%AF%B9%E4%BA%BA%E4%BD%93%E8%BF%9B%E8%A1%8C%E4%B8%89%E7%BB%B4%E5%BB%BA%E6%A8%A1%EF%BC%9F.html","title":"023 _ CVPR 2018论文精读：如何从整体上对人体进行三维建模？","lang":"zh-CN","frontmatter":{"description":"023 _ CVPR 2018论文精读：如何从整体上对人体进行三维建模？ 今天我们来分享CVPR大会的最佳学生论文，标题是《全方位捕捉：用于跟踪面部表情，手势和身体运动的3D变形模型》（Total Capture: A 3D Deformation Model for Tracking Faces, Hands and Bodies）。 很多学术会议都...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/interview/posts/AI%E6%8A%80%E6%9C%AF%E5%86%85%E5%8F%82/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9B%BD%E9%99%85%E9%A1%B6%E7%BA%A7%E4%BC%9A%E8%AE%AE/023%20_%20CVPR%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BB%8E%E6%95%B4%E4%BD%93%E4%B8%8A%E5%AF%B9%E4%BA%BA%E4%BD%93%E8%BF%9B%E8%A1%8C%E4%B8%89%E7%BB%B4%E5%BB%BA%E6%A8%A1%EF%BC%9F.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"023 _ CVPR 2018论文精读：如何从整体上对人体进行三维建模？"}],["meta",{"property":"og:description","content":"023 _ CVPR 2018论文精读：如何从整体上对人体进行三维建模？ 今天我们来分享CVPR大会的最佳学生论文，标题是《全方位捕捉：用于跟踪面部表情，手势和身体运动的3D变形模型》（Total Capture: A 3D Deformation Model for Tracking Faces, Hands and Bodies）。 很多学术会议都..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-16T11:19:38.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-16T11:19:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"023 _ CVPR 2018论文精读：如何从整体上对人体进行三维建模？\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-08-16T11:19:38.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1755343178000,"updatedTime":1755343178000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":1,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":7.16,"words":2147},"filePathRelative":"posts/AI技术内参/人工智能国际顶级会议/023 _ CVPR 2018论文精读：如何从整体上对人体进行三维建模？.md","localizedDate":"2025年8月16日","excerpt":"\\n<p><audio id=\\"audio\\" title=\\"023 | CVPR 2018论文精读：如何从整体上对人体进行三维建模？\\" controls=\\"\\" preload=\\"none\\"><source id=\\"mp3\\" src=\\"https://static001.geekbang.org/resource/audio/81/f4/8183ffd2d1c3e1c4a1c07bef6b80e0f4.mp3\\"></audio></p>\\n<p>今天我们来分享CVPR大会的最佳学生论文，标题是《全方位捕捉：用于跟踪面部表情，手势和身体运动的3D变形模型》（<a href=\\"http://www.cs.cmu.edu/~hanbyulj/totalbody/totalcapture.pdf\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Total Capture: A 3D Deformation Model for Tracking Faces, Hands and Bodies</a>）。</p>","autoDesc":true}');export{d as comp,B as data};
