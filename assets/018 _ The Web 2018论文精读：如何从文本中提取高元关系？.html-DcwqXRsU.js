import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as r,o}from"./app-d8EKP-K0.js";const n={};function s(i,e){return o(),a("div",null,e[0]||(e[0]=[r('<h1 id="_018-the-web-2018论文精读-如何从文本中提取高元关系" tabindex="-1"><a class="header-anchor" href="#_018-the-web-2018论文精读-如何从文本中提取高元关系"><span>018 _ The Web 2018论文精读：如何从文本中提取高元关系？</span></a></h1><p><audio id="audio" title="018 | The Web 2018论文精读：如何从文本中提取高元关系？" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/73/4d/738339e0acafabf51dad743e363eb84d.mp3"></audio></p><p>今天我们来看万维网大会2018的最佳论文，标题是“HighLife: Higher-arity Fact Harvesting”。作者都来自德国著名的“马克斯·普朗克计算机科学研究所”（Max Plank Institute for Informatics）。这个研究所是德国最大的基础科学研究组织“马克斯·普朗克学会”（Max-Planck-Gesellschaft）的分支研究机构，致力于在科学刊物上发表新的研究成果，开发软件系统和培养新的科学研究工作者。马克斯·普朗克学会因其杰出的科研成果在德国甚至全世界都获得了很高的声誉。</p><h2 id="什么是高元关系" tabindex="-1"><a class="header-anchor" href="#什么是高元关系"><span>什么是高元关系？</span></a></h2><p>这篇论文主要是涉及到<strong>高元（Higher-Artiy）关系</strong>的提取。那什么是高元关系呢？</p><p>传统的信息提取和知识库主要是关注二元关系的提取和存储。例如，我们可以知道居里夫人分别于1903年和1911年获得了诺贝尔奖。但是关系数据库中并不知道这两年的奖项分别是物理和化学。同理，我们可以在知识库中存放居里夫人获得过诺贝尔物理奖以及诺贝尔化学奖的信息，但是就无法和1903年和1911年这两个信息进行配对。通过这个例子我们可以看出，基于二元关系的信息提取和知识库虽然简单易行，但是有其先天的局限性。</p><p>这篇论文要讨论的高元关系，就是希望能够直接对“居里夫人在1903年获得了诺贝尔物理学奖”这样的三元甚至更高元的关系进行提取和表征。作者们认为这篇论文是较少的关注高元关系提取的先驱工作。</p><h2 id="论文的主要贡献" tabindex="-1"><a class="header-anchor" href="#论文的主要贡献"><span>论文的主要贡献</span></a></h2><p>我们刚才说了，这篇论文的一个重要贡献就是针对高元关系的提取所作出了很多努力。</p><p>具体来说，作者们使用“<strong>种子事实</strong>”（Seed Facts）作为一种监督信息来学习<strong>模式</strong>（Patterns），并且利用这些学习到的模式来寻找更多的“<strong>候选事实</strong>”（Facts Candidates），如此循环。这是把过去的一种针对二元关系提取的方法给扩展到高元关系。这个方法的潜在问题是：在能够保证“高召回”（High Recall）的情况下，得到的很多关系可能存在“<strong>噪声</strong>”和“<strong>目标浮动</strong>”（Target Drifts）。这里所说的目标浮动指的是我们提取的事实有可能存在主题上的偏差。</p><p>为了解决这个问题，作者们在这篇论文里利用了“<strong>限制推理</strong>”（Constraint Reasoning），来对已经得到的事实进一步筛选以得到最后的结果。这里的限制可以是“类型”（Type）上的，比如，我们限制提取到的普利策奖为“书籍”而非“电影”或“音乐”。通过这些在取值或者类型上的限制，我们可以对获取到的事实进行清理。</p><p>论文解决的另外一个难点就是很多高元信息在原始的文本中就是缺失的，或者是不完全的。比如，“Google于2014年收购了Nest”这个事实就没有提及金额，而“Google以32亿美元收购了Nest”这个事实又没有提及时间。作者们针对这个情况，把整个框架给扩展到了缺失信息中，从而能够从原始文本中拼凑多元关系。</p><h2 id="论文的核心方法" tabindex="-1"><a class="header-anchor" href="#论文的核心方法"><span>论文的核心方法</span></a></h2><p>文章提出了一个由好几个组件组成的系统用于信息的提取。</p><p>首先，有一个叫作 <strong>NERD</strong>的组件，即“人名识别和去歧义”组件，用于从句子中提取不同的“实体”。这里面运用到了很多外部的信息库，比如医疗生物实体库“联合医疗语言系统”（Unified Medical Language System）、支持新闻实体的AIDA系统以及WordNet语料库。同时，在这个部分，NERD还依赖于“斯坦福自然语言处理核心库”（Stanford CoreNLP）提供“人名识别”以及“词类分析”（Part of Speech）等基础功能。</p><p>在提取了人名和实体名之后，作者们就开始构建一个从词类分析得到的<strong>树型数据结构</strong>。这个数据结构的目的是反映N元关系和内部信息的架构。这个部分基本上也是依赖传统的自然语言处理所得到的树结构，只不过进行了简单的修正。</p><p>得到树结构之后，接下来的一系列工作都是<strong>在这个树结构上获取不同的模式，从而能够得到想要的高元关系</strong>。这里面有很多细节，我们在这里就不赘述了。比如，作者们利用“<strong>树挖掘</strong>”（Tree Mining）技术来发现频繁出现的子树结构，从而认定某个子树模式是不是一个好的候选事实。这里的思路其实和经典的“<strong>频繁模式挖掘</strong>”（Frequent Pattern Mining）一样，都是去不断地计算一个结构的“<strong>支持度</strong>”（Support）和“<strong>置信度</strong>”（Confidence），从而通过两个值来决定是不是要把这个模式给留下来。</p><p>除此以外，这一部分的部件还需要支持“<strong>部分N元候选事实</strong>”（Partial N-ary Fact Candidate）的匹配。之前我们也讲过了，这个功能也算是这篇论文的一个贡献。这里面的重要职能就是能够对树的一部分结构进行匹配，而不需要对所有的部分都能够完全一致。</p><p>当作者们通过树挖掘从而发现了基本的候选事实之后，下面需要做的工作就是针对这些候选事实进行推理盘查，看是不是所有的事实都能经得住推敲。也就是说，我们需要查看有没有存在多个事实不一致的地方。</p><p>需要指出的是，从整体上来看，所有组件的流程基本上都是<strong>无监督的数据挖掘操作</strong>。也就是说，整个系统并不需要依赖于什么训练数据。</p><h2 id="方法的实验效果" tabindex="-1"><a class="header-anchor" href="#方法的实验效果"><span>方法的实验效果</span></a></h2><p>作者们在纽约时报数据集以及PubMed数据集上都进行了实验，主要观测的指标是“<strong>精度</strong>”（Precision）。我们之前提到过，这篇文章所研究的高元关系提取，这个问题很新颖。因此，作者们还利用CrowdFlower众包平台来获取了数据的标签，用于检测所提取关系的准确度。当然这部分数据量相对来说是比较小的。</p><p>从实验的效果上来说，文章提出的方法能够达到平均接近80%~90%的精度，这可以说是非常令人振奋的结果了，而达到这样的结果仅仅需要几百个种子事实。</p><h2 id="小结" tabindex="-1"><a class="header-anchor" href="#小结"><span>小结</span></a></h2><p>今天我为你讲了今年万维网大会的优秀论文。文章介绍了如何从文本中提取高元关系，这是一个比较新的研究领域。</p><p>一起来回顾下要点：第一，我们简单讨论了高元关系的含义；第二，我们重点介绍了论文的主要贡献和核心思路；第三，我们简单分享了提出方法的实验成果。</p><p>最后，给你留一个思考题，在什么样的应用中，我们可以利用到这篇文章提出的高元关系？</p><p>欢迎你给我留言，和我一起讨论。</p>',28)]))}const h=t(n,[["render",s]]),g=JSON.parse('{"path":"/posts/AI%E6%8A%80%E6%9C%AF%E5%86%85%E5%8F%82/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9B%BD%E9%99%85%E9%A1%B6%E7%BA%A7%E4%BC%9A%E8%AE%AE/018%20_%20The%20Web%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BB%8E%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%90%E5%8F%96%E9%AB%98%E5%85%83%E5%85%B3%E7%B3%BB%EF%BC%9F.html","title":"018 _ The Web 2018论文精读：如何从文本中提取高元关系？","lang":"zh-CN","frontmatter":{"description":"018 _ The Web 2018论文精读：如何从文本中提取高元关系？ 今天我们来看万维网大会2018的最佳论文，标题是“HighLife: Higher-arity Fact Harvesting”。作者都来自德国著名的“马克斯·普朗克计算机科学研究所”（Max Plank Institute for Informatics）。这个研究所是德国最大...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/interview/posts/AI%E6%8A%80%E6%9C%AF%E5%86%85%E5%8F%82/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9B%BD%E9%99%85%E9%A1%B6%E7%BA%A7%E4%BC%9A%E8%AE%AE/018%20_%20The%20Web%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BB%8E%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%90%E5%8F%96%E9%AB%98%E5%85%83%E5%85%B3%E7%B3%BB%EF%BC%9F.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"018 _ The Web 2018论文精读：如何从文本中提取高元关系？"}],["meta",{"property":"og:description","content":"018 _ The Web 2018论文精读：如何从文本中提取高元关系？ 今天我们来看万维网大会2018的最佳论文，标题是“HighLife: Higher-arity Fact Harvesting”。作者都来自德国著名的“马克斯·普朗克计算机科学研究所”（Max Plank Institute for Informatics）。这个研究所是德国最大..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-16T11:19:38.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-16T11:19:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"018 _ The Web 2018论文精读：如何从文本中提取高元关系？\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-08-16T11:19:38.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1755343178000,"updatedTime":1755343178000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":1,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":6.59,"words":1977},"filePathRelative":"posts/AI技术内参/人工智能国际顶级会议/018 _ The Web 2018论文精读：如何从文本中提取高元关系？.md","localizedDate":"2025年8月16日","excerpt":"\\n<p><audio id=\\"audio\\" title=\\"018 | The Web 2018论文精读：如何从文本中提取高元关系？\\" controls=\\"\\" preload=\\"none\\"><source id=\\"mp3\\" src=\\"https://static001.geekbang.org/resource/audio/73/4d/738339e0acafabf51dad743e363eb84d.mp3\\"></audio></p>\\n<p>今天我们来看万维网大会2018的最佳论文，标题是“HighLife: Higher-arity Fact Harvesting”。作者都来自德国著名的“马克斯·普朗克计算机科学研究所”（Max Plank Institute for Informatics）。这个研究所是德国最大的基础科学研究组织“马克斯·普朗克学会”（Max-Planck-Gesellschaft）的分支研究机构，致力于在科学刊物上发表新的研究成果，开发软件系统和培养新的科学研究工作者。马克斯·普朗克学会因其杰出的科研成果在德国甚至全世界都获得了很高的声誉。</p>","autoDesc":true}');export{h as comp,g as data};
