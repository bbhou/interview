import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as n,o as p}from"./app-d8EKP-K0.js";const i={};function r(o,e){return p(),a("div",null,e[0]||(e[0]=[n(`<h1 id="特别加餐-tensorflow的模型离线评估实践怎么做" tabindex="-1"><a class="header-anchor" href="#特别加餐-tensorflow的模型离线评估实践怎么做"><span>特别加餐｜TensorFlow的模型离线评估实践怎么做？</span></a></h1><p><audio id="audio" title="特别加餐｜TensorFlow的模型离线评估实践怎么做？" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/77/e7/7704d444f9fe7741752e41586dc4a6e7.mp3"></audio></p><p>你好，我是王喆。</p><p>上两节课，我们学习了离线评估的主要方法以及离线评估的主要指标。那这些方法和指标具体是怎么使用的，会遇到哪些问题呢？我们之前实现的深度学习模型的效果怎么样呢？</p><p>这节课，我们直接进入实战，在TensorFlow环境下评估一下我们之前实现过的深度学习模型。一方面这能帮助我们进一步加深对离线评估方法和指标的理解，另一方面，也能检验一下我们自己模型的效果。</p><h2 id="训练集和测试集的生成" tabindex="-1"><a class="header-anchor" href="#训练集和测试集的生成"><span>训练集和测试集的生成</span></a></h2><p>离线评估的第一步就是要生成训练集和测试集，在这次的评估实践中，我会选择最常用的Holdout检验的方式来划分训练集和测试集。划分的方法我们已经在<a href="https://time.geekbang.org/column/article/317114" target="_blank" rel="noopener noreferrer">第23讲</a>里用Spark实现过了，就是调用Spark中的randomSplit函数进行划分，具体的代码你可以参考 FeatureEngForRecModel对象中的splitAndSaveTrainingTestSamples函数。</p><p>这里我们按照8:2的比例把全量样本集划分为训练集和测试集，再把它们分别存储在<code>SparrowRecSys/src/main/resources/webroot/sampledata/trainingSamples.csv</code>和<code>SparrowRecSys/src/main/resources/webroot/sampledata/testSamples.csv</code>路径中。</p><p>在TensorFlow内部，我们跟之前载入数据集的方式一样，调用<code>get_dataset</code>方法分别载入训练集和测试集就可以了。</p><h2 id="tensorflow评估指标的设置" tabindex="-1"><a class="header-anchor" href="#tensorflow评估指标的设置"><span>TensorFlow评估指标的设置</span></a></h2><p>在载入训练集和测试集后，我们需要搞清楚如何在TensorFlow中设置评估指标，并通过这些指标观察模型在每一轮训练上的效果变化，以及最终在测试集上的表现。这个过程听起来还挺复杂，好在，TensorFlow已经为我们提供了非常丰富的评估指标，这让我们可以在模型编译阶段设置metrics来指定想要使用的评估指标。</p><p>具体怎么做呢？我们一起来看看下面的代码，它是设置评估指标的一个典型过程。首先，我们在model complie阶段设置准确度（Accuracy）、ROC曲线AUC（tf.keras.metrics.AUC(curve=&#39;ROC&#39;)）、PR曲线AUC（tf.keras.metrics.AUC(curve=&#39;PR&#39;)），这三个在评估推荐模型时最常用的指标。</p><p>同时，在训练和评估过程中，模型还会默认产生损失函数loss这一指标。在模型编译时我们采用了binary_crossentropy作为损失函数，所以这里的Loss指标就是我们在上一节课介绍过的二分类问题的模型损失Logloss。</p><p>在设置好评估指标后，模型在每轮epoch结束后都会输出这些评估指标的当前值。在最后的测试集评估阶段，我们可以调用model.evaluate函数来生成测试集上的评估指标。具体的实现代码，你可以参考SparrowRecsys项目中深度推荐模型相关的代码。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span># compile the model, set loss function, optimizer and evaluation metrics</span></span>
<span class="line"><span>model.compile(</span></span>
<span class="line"><span>    loss=&#39;binary_crossentropy&#39;,</span></span>
<span class="line"><span>    optimizer=&#39;adam&#39;,</span></span>
<span class="line"><span>    metrics=[&#39;accuracy&#39;, tf.keras.metrics.AUC(curve=&#39;ROC&#39;), tf.keras.metrics.AUC(curve=&#39;PR&#39;)])</span></span>
<span class="line"><span># train the model</span></span>
<span class="line"><span>model.fit(train_dataset, epochs=5)</span></span>
<span class="line"><span># evaluate the model</span></span>
<span class="line"><span>test_loss, test_accuracy, test_roc_auc, test_pr_auc = model.evaluate(test_dataset)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在执行这段代码的时候，它的输出是下面这样的。从中，我们可以清楚地看到每一轮训练的Loss、Accuracy、ROC AUC、PR AUC这四个指标的变化，以及最终在测试集上这四个指标的结果。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Epoch 1/5</span></span>
<span class="line"><span>8236/8236 [==============================] - 60s 7ms/step - loss: 3.0724 - accuracy: 0.5778 - auc: 0.5844 - auc_1: 0.6301</span></span>
<span class="line"><span>Epoch 2/5</span></span>
<span class="line"><span>8236/8236 [==============================] - 55s 7ms/step - loss: 0.6291 - accuracy: 0.6687 - auc: 0.7158 - auc_1: 0.7365</span></span>
<span class="line"><span>Epoch 3/5</span></span>
<span class="line"><span>8236/8236 [==============================] - 56s 7ms/step - loss: 0.5555 - accuracy: 0.7176 - auc: 0.7813 - auc_1: 0.8018</span></span>
<span class="line"><span>Epoch 4/5</span></span>
<span class="line"><span>8236/8236 [==============================] - 56s 7ms/step - loss: 0.5263 - accuracy: 0.7399 - auc: 0.8090 - auc_1: 0.8305</span></span>
<span class="line"><span>Epoch 5/5</span></span>
<span class="line"><span>8236/8236 [==============================] - 56s 7ms/step - loss: 0.5071 - accuracy: 0.7524 - auc: 0.8256 - auc_1: 0.8481</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span>1000/1000 [==============================] - 5s 5ms/step - loss: 0.5198 - accuracy: 0.7427 - auc: 0.8138 - auc_1: 0.8430</span></span>
<span class="line"><span>Test Loss 0.5198314250707626, Test Accuracy 0.7426666617393494, Test ROC AUC 0.813848614692688, Test PR AUC 0.8429719805717468</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>总的来说，随着训练的进行，模型的Loss在降低，而Accuracy、Roc AUC、Pr AUC这几个指标都在升高，这证明模型的效果随着训练轮数的增加在逐渐变好。</p><p>最终，我们就得到了测试集上的评估指标。你会发现，测试集上的评估结果相比训练集有所下降，比如Accuracy从0.7524下降到了0.7427，ROC AUC从0.8256下降到了0.8138。这是非常正常的现象，因为模型在训练集上都会存在着轻微过拟合的情况。</p><p>如果测试集的评估结果相比训练集出现大幅下降，比如下降幅度超过了5%，就说明模型产生了非常严重的过拟合现象，我们就要反思一下是不是在模型设计过程中出现了一些问题，比如模型的结构对于这个问题来说过于复杂，模型的层数或者每层的神经元数量过多，或者我们要看一看是不是需要加入Dropout，正则化项来减轻过拟合的风险。</p><p>除了观察模型自己的效果，在模型评估阶段，我们更应该重视不同模型之间的对比，这样才能确定我们最终上线的模型，下面我们就做一个模型效果的横向对比。</p><h2 id="模型的效果对比" tabindex="-1"><a class="header-anchor" href="#模型的效果对比"><span>模型的效果对比</span></a></h2><p>在推荐模型篇，我们已经实现了EmbeddingMLP、NerualCF、Wide&amp;Deep以及DeepFM这四个深度学习模型，后来还有同学添加了DIN的模型实现。</p><p>那接下来，我们就利用这节课的模型评估方法，来尝试对比一下这几个模型的效果。首先，我直接把这些模型在测试集上的评估结果记录到了表格里，当然，我更建议你利用SparrowRecsys项目中的代码，自己来计算一下，多实践一下我们刚才说的模型评估方法。</p><img src="https://static001.geekbang.org/resource/image/06/c3/067c96ed1a4d59b1e2a8d610cb6888c3.jpeg" alt=""><p>通过上面的比较，我们可以看出，Embedding MLP和Wide&amp;Deep模型在我们的MovieLens这个小规模数据集上的效果最好，它们两个的指标也非常接近，只不过是在不同指标上有细微的差异，比如模型Loss指标上Wide&amp;Deep模型好一点，在Accuracy、ROC AUC、PR AUC指标上Embedding MLP模型好一点。</p><p>遇到这种情况，我们该如何挑出更好的那个模型呢？一般我们会在两个方向上做尝试：一是做进一步的模型调参，特别是对于复杂一点的Wide&amp;Deep模型，我们可以尝试通过参数的Fine Tuning（微调）让模型达到更好的效果；二是如果经过多次尝试两个模型的效果仍比较接近，我们就通过线上评选出最后的胜出者。</p><p>说完了效果好的指标，不知道你有没有注意到一个反常的现象，那就是模型DeepFM的评估结果非常奇怪，怎么个奇怪法呢？理论上来说，DeepFM的表达能力是最强的，可它现在展示出来的评估结果却最差。这种情况就极有可能是因为模型遇到了过拟合问题。为了验证个想法，我们再来看一下DeepFM在训练集上的表现，如下表所示：</p><img src="https://static001.geekbang.org/resource/image/e6/41/e659147e8da20228ed722e3f38eea641.jpeg" alt=""><p>我们很惊讶地发现，DeepFM在测试集上的表现比训练集差了非常多。毫无疑问，这个模型过拟合了。当然，这里面也有我们数据的因素，因为我们采用了一个规模很小的采样过的MovieLens数据集，在训练复杂模型时，小数据集往往更难让模型收敛，并且由于训练不充分的原因，模型中很多参数其实没有达到稳定的状态，因此在测试集上的表现往往会呈现出比较大的随机性。</p><p>通过DeepFM模型效果对比的例子，也再一次印证了我们在<a href="https://time.geekbang.org/column/article/315620" target="_blank" rel="noopener noreferrer">“最优的模型结构该怎么找？”</a>那节课的结论：推荐模型没有银弹，每一个业务，每一类数据，都有最合适的模型结构，并不是说最复杂的，最新的模型结构就是最好的模型结构，我们需要因地制宜地调整模型和参数，这才是算法工程师最大的价值所在。</p><h2 id="小结" tabindex="-1"><a class="header-anchor" href="#小结"><span>小结</span></a></h2><p>这节实践课，我们基于TensorFlow进行了深度推荐模型的评估，整个实践过程可以分成三步。</p><p>第一步是导入Spark分割好的训练集和测试集。</p><p>第二步是在TensorFlow中设置评估指标，再在测试集上调用model.evaluate函数计算这些评估指标。在实践过程中，我们要清楚有哪些TensorFlow的指标可以直接调用。那在这节课里，我们用到了最常用的Loss、Accuracy、ROC AUC、PR AUC四个指标。</p><p>第三步是根据四个深度推荐模型的评估结果，进行模型效果的对比。通过对比的结果我们发现Embedding MLP和Wide&amp;Deep的效果是最好的。同时，我们也发现，本该表现很好的DeepFM模型，它的评估结果却比较差，原因是模型产生了非常严重的过拟合问题。</p><p>因此，在实际工作中，我们需要通过不断调整模型结构、模型参数，来找到最合适当前业务和数据集的模型。</p><h2 id="课后思考" tabindex="-1"><a class="header-anchor" href="#课后思考"><span>课后思考</span></a></h2><p>1.除了这节课用到的Loss、Accuracy、ROC AUC、PR AUC这四个指标，你在TensorFlow的实践中还会经常用到哪些评估指标呢？ 你能把这些常用指标以及它们特点分享出来吗？（你可以参考TensorFlow的官方<a href="https://tensorflow.google.cn/api_docs/python/tf/keras/metrics" target="_blank" rel="noopener noreferrer">Metrics文档</a> ）</p><p>2.你认为DeepFM评估结果这么差的原因，除了过拟合，还有什么更深层次的原因呢？可以尝试从模型结构的原理上给出一些解释吗？</p><p>期待在留言区看到你对DeepFM模型的思考和使用评估指标的经验，我们下节课见！</p>`,41)]))}const l=s(i,[["render",r]]),d=JSON.parse('{"path":"/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AF%87/%E7%89%B9%E5%88%AB%E5%8A%A0%E9%A4%90%EF%BD%9CTensorFlow%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BC%B0%E5%AE%9E%E8%B7%B5%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F.html","title":"特别加餐｜TensorFlow的模型离线评估实践怎么做？","lang":"zh-CN","frontmatter":{"description":"特别加餐｜TensorFlow的模型离线评估实践怎么做？ 你好，我是王喆。 上两节课，我们学习了离线评估的主要方法以及离线评估的主要指标。那这些方法和指标具体是怎么使用的，会遇到哪些问题呢？我们之前实现的深度学习模型的效果怎么样呢？ 这节课，我们直接进入实战，在TensorFlow环境下评估一下我们之前实现过的深度学习模型。一方面这能帮助我们进一步加深...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/interview/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%AF%87/%E7%89%B9%E5%88%AB%E5%8A%A0%E9%A4%90%EF%BD%9CTensorFlow%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BC%B0%E5%AE%9E%E8%B7%B5%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"特别加餐｜TensorFlow的模型离线评估实践怎么做？"}],["meta",{"property":"og:description","content":"特别加餐｜TensorFlow的模型离线评估实践怎么做？ 你好，我是王喆。 上两节课，我们学习了离线评估的主要方法以及离线评估的主要指标。那这些方法和指标具体是怎么使用的，会遇到哪些问题呢？我们之前实现的深度学习模型的效果怎么样呢？ 这节课，我们直接进入实战，在TensorFlow环境下评估一下我们之前实现过的深度学习模型。一方面这能帮助我们进一步加深..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-16T11:19:38.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-16T11:19:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"特别加餐｜TensorFlow的模型离线评估实践怎么做？\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-08-16T11:19:38.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1755343178000,"updatedTime":1755343178000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":1,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":8.52,"words":2556},"filePathRelative":"posts/深度学习推荐系统实战/模型评估篇/特别加餐｜TensorFlow的模型离线评估实践怎么做？.md","localizedDate":"2025年8月16日","excerpt":"\\n<p><audio id=\\"audio\\" title=\\"特别加餐｜TensorFlow的模型离线评估实践怎么做？\\" controls=\\"\\" preload=\\"none\\"><source id=\\"mp3\\" src=\\"https://static001.geekbang.org/resource/audio/77/e7/7704d444f9fe7741752e41586dc4a6e7.mp3\\"></audio></p>\\n<p>你好，我是王喆。</p>\\n<p>上两节课，我们学习了离线评估的主要方法以及离线评估的主要指标。那这些方法和指标具体是怎么使用的，会遇到哪些问题呢？我们之前实现的深度学习模型的效果怎么样呢？</p>","autoDesc":true}');export{l as comp,d as data};
